{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/work/EAGLE/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 14:46:21,958] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conversation(name='llama-3', system_template='<|start_header_id|>system<|end_header_id|>\\n\\n{system_message}<|eot_id|>', system_message='', system_message_vision='', roles=('user', 'assistant'), messages=[], offset=0, sep_style=<SeparatorStyle.LLAMA3: 8>, sep='', sep2=None, stop_str='<|eot_id|>', stop_token_ids=[128001, 128009], max_image_size_mb=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastchat.model import get_conversation_template\n",
    "\n",
    "\n",
    "conv = get_conversation_template('/models/Meta-Llama-3-8B-Instruct')\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/models/Meta-Llama-3-8B-Instruct', use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained('/models/Meta-Llama-3-8B-Instruct', device_map=\"cuda\", torch_dtype=torch.float16)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\\\n\\\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "\t{\"role\": \"system\", \"content\": \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\\\n\\\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"},\n",
    "\t{\"role\": \"user\", \"content\": \"Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...\"},\n",
    "]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "\tconv.append_message(msg['role'], msg['content'])\n",
    "\n",
    "conv.append_message('assistant', '')\n",
    "\n",
    "prompt = conv.get_prompt()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 152]),\n",
       " tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,  11190,\n",
       "              11,  49150,    323,  10978,  18328,     13,  24119,   4320,    439,\n",
       "            1520,   3725,    439,   3284,     11,   1418,   1694,   6220,     13,\n",
       "             220,   4718,  11503,   1288,    539,   2997,    904,  28856,     11,\n",
       "           89735,     11,  25185,     11,  64882,     11,  21503,     11,  11660,\n",
       "              11,    477,  12079,   2262,     13,   5321,   6106,    430,    701,\n",
       "           14847,    527,  40418,  74315,    323,   6928,    304,   7138,   7255,\n",
       "              77,   1734,   2746,    264,   3488,   1587,    539,   1304,    904,\n",
       "            5647,     11,    477,    374,    539,   2144,   1870,  56887,     11,\n",
       "           10552,   3249,   4619,    315,  36864,   2555,    539,   4495,     13,\n",
       "            1442,    499,   1541,    956,   1440,    279,   4320,    311,    264,\n",
       "            3488,     11,   4587,   1541,    956,   4430,    905,   2038,     13,\n",
       "          128009, 128006,    882, 128007,    271,   9370,   5730,    553,    279,\n",
       "            1925,   6848,    315,  12149,  23074,    596,   5761,  24083,  31922,\n",
       "            1139,  17889,   3585,    439,    433,  18713,   1771,    311,    264,\n",
       "            6650,   8661,   9266,  25976,   1521,  15174,    323,  26411,    369,\n",
       "             872,   8403,   1131, 128009, 128006,  78191, 128007,    271]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(prompt, return_tensors='pt', add_special_tokens=False).cuda()\n",
    "input_ids.shape, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 152]),\n",
       " tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,  11190,\n",
       "              11,  49150,    323,  10978,  18328,     13,  24119,   4320,    439,\n",
       "            1520,   3725,    439,   3284,     11,   1418,   1694,   6220,     13,\n",
       "             220,   4718,  11503,   1288,    539,   2997,    904,  28856,     11,\n",
       "           89735,     11,  25185,     11,  64882,     11,  21503,     11,  11660,\n",
       "              11,    477,  12079,   2262,     13,   5321,   6106,    430,    701,\n",
       "           14847,    527,  40418,  74315,    323,   6928,    304,   7138,   7255,\n",
       "              77,   1734,   2746,    264,   3488,   1587,    539,   1304,    904,\n",
       "            5647,     11,    477,    374,    539,   2144,   1870,  56887,     11,\n",
       "           10552,   3249,   4619,    315,  36864,   2555,    539,   4495,     13,\n",
       "            1442,    499,   1541,    956,   1440,    279,   4320,    311,    264,\n",
       "            3488,     11,   4587,   1541,    956,   4430,    905,   2038,     13,\n",
       "          128009, 128006,    882, 128007,    271,   9370,   5730,    553,    279,\n",
       "            1925,   6848,    315,  12149,  23074,    596,   5761,  24083,  31922,\n",
       "            1139,  17889,   3585,    439,    433,  18713,   1771,    311,    264,\n",
       "            6650,   8661,   9266,  25976,   1521,  15174,    323,  26411,    369,\n",
       "             872,   8403,   1131, 128009, 128006,  78191, 128007,    271]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids2 = torch.as_tensor(tokenizer([prompt], add_special_tokens=False).input_ids)\n",
    "ids2.shape, ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(input_ids[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/work/EAGLE/env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/root/work/EAGLE/env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 617]),\n",
       " tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,  11190,\n",
       "              11,  49150,    323,  10978,  18328,     13,  24119,   4320,    439,\n",
       "            1520,   3725,    439,   3284,     11,   1418,   1694,   6220,     13,\n",
       "             220,   4718,  11503,   1288,    539,   2997,    904,  28856,     11,\n",
       "           89735,     11,  25185,     11,  64882,     11,  21503,     11,  11660,\n",
       "              11,    477,  12079,   2262,     13,   5321,   6106,    430,    701,\n",
       "           14847,    527,  40418,  74315,    323,   6928,    304,   7138,   7255,\n",
       "              77,   1734,   2746,    264,   3488,   1587,    539,   1304,    904,\n",
       "            5647,     11,    477,    374,    539,   2144,   1870,  56887,     11,\n",
       "           10552,   3249,   4619,    315,  36864,   2555,    539,   4495,     13,\n",
       "            1442,    499,   1541,    956,   1440,    279,   4320,    311,    264,\n",
       "            3488,     11,   4587,   1541,    956,   4430,    905,   2038,     13,\n",
       "          128009, 128006,    882, 128007,    271,   9370,   5730,    553,    279,\n",
       "            1925,   6848,    315,  12149,  23074,    596,   5761,  24083,  31922,\n",
       "            1139,  17889,   3585,    439,    433,  18713,   1771,    311,    264,\n",
       "            6650,   8661,   9266,  25976,   1521,  15174,    323,  26411,    369,\n",
       "             872,   8403,   1131, 128009, 128006,  78191, 128007,    271,  39727,\n",
       "           23074,    596,   5761,  24083,  31922,    374,    264,  16195,   8446,\n",
       "             369,  28818,    323,   8661,   3956,    477,   3600,     13,   5810,\n",
       "             596,    264,  12399,    315,    279,   1925,   6848,    304,  17889,\n",
       "            3585,     11,  41891,    311,    264,   6650,   8661,   9266,  25976,\n",
       "            1521,  15174,    323,  26411,    369,    872,   8403,   1473,    334,\n",
       "            4808,   8288,  18930,  28673,  57277,      9,  65647,    323,   9788,\n",
       "             264,  34235,  35149,    477,   3157,    369,    701,   8403,    198,\n",
       "               9,   4324,    264,   5647,    315,  50919,    323,  31293,    555,\n",
       "           11821,  15525,   2262,    323,  26793,    198,      9,   8012,    264,\n",
       "            1160,    315,   4754,   6444,    323,   5813,    264,   5133,    449,\n",
       "            1124,    198,      9,   8000,    264,   5016,  11486,  41180,    320,\n",
       "            2078,     47,      8,    323,    264,  29722,   3446,    369,    701,\n",
       "            8403,      6,   3956,    477,   3600,    271,    334,   4808,   8288,\n",
       "           18930,  29971,  57277,      9,   4324,    264,   4101,    315,  15525,\n",
       "              11,  39319,     11,    323,  23387,   2262,   9863,    320,     68,\n",
       "            1326,   2637,   6946,     11,   5117,   8158,     11,  55346,      8,\n",
       "             430,  39170,    323,  46276,    701,  10877,    198,      9,  12037,\n",
       "            1521,   2262,   9863,    449,    701,   1160,     11,   4857,  50919,\n",
       "             323,  28361,    369,    279,   7195,    198,      9,   5560,    420,\n",
       "            8668,    311,   5813,    701,   9266,    439,    264,   3463,   7808,\n",
       "             323,  11447,    304,    279,  35149,    271,    334,  33167,  28673,\n",
       "           57277,      9,   4324,    264,   5647,    315,  54917,    323,  82484,\n",
       "             555,  10209,   7347,   7394,  33321,     11,  32162,     11,    477,\n",
       "           14079,   2680,    311,    701,   8403,      6,   3956,    477,   3600,\n",
       "             198,      9,   5560,    264,   4101,    315,  14633,    323,   1023,\n",
       "            8661,   7384,    311,   1977,  28361,    323,  50919,    369,    279,\n",
       "            7195,    198,      9,  10984,  61140,    701,  10877,    311,   1935,\n",
       "            1957,    555,  10209,    264,   2867,   1650,   4791,  26115,    320,\n",
       "            1182,     32,      8,    323,   3339,    433,   4228,    369,   1124,\n",
       "             311,   3780,    198,      9,   5560,   3674,  11311,     11,   1778,\n",
       "             439,  84610,    323,   8544,     11,    311,   1977,  38769,    323,\n",
       "            7095,    271,    334,   4226,   8288,  18930,  28673,  57277,      9,\n",
       "           11359,    709,    449,    701,  10877,    311,   6106,    814,   2351,\n",
       "           20097,    449,    872,   7782,    323,    311,   9762,  11302,    198,\n",
       "               9,  15353,    311,   3493,    907,    323,   1862,    311,    701,\n",
       "           10877,     11,   4857,    264,  29947,   4029,   2212,    701,   8403,\n",
       "               6,   3956,    477,   3600,    198,      9,   5560,    420,   6776,\n",
       "             311,  33834,    616,    477,   5425,   1355,    616,   5552,   3956,\n",
       "             477,   3600,     11,    477,    311,  12192,   3938,  38175,    271,\n",
       "             334,   1622,  58014,  57277,      9,  26891,    389,   8405,  38883,\n",
       "             907,    311,    701,  10877,     11,   4856,   1109,   1120,   4560,\n",
       "             311,   1304,    264,   6412,    198,      9,   8012,  12135,    323,\n",
       "            7095,    449,    701,  10877,     11,   4856,   1109,   1120,   4560,\n",
       "             311,   1304,    264,   4062,  22786,    198,      9,   5560,  48929,\n",
       "             323,  14604,  13537,    311,   1304,    701,   8403,      6,   3956,\n",
       "             477,   3600,    810,   1375,  15436,    323,  33352,    198,      9,\n",
       "            2893,  13513,     11,  18300,     11,    323,  10978,    304,    682,\n",
       "             701,   8661,   9045,    271,   1383,  25976,   1521,  15174,    323,\n",
       "           26411,     11,    264,   6650,   8661,   9266,    649,   1520,    872,\n",
       "            8403,   7946,   7195,    323,   3157,    872,   3956,    477,   3600,\n",
       "              11,   4857,    264,  29947,  10877,    323,  10043,   1317,   9860,\n",
       "            6650,    323,   2450,     13, 128009]], device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=False,\n",
    "\ttemperature=0,\n",
    ")\n",
    "output.shape, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Jeff Walker's Product Launch Formula is a comprehensive strategy for launching and marketing products or services. Here's a summary of the main ideas in bullet points, tailored to a growth marketing agency implementing these strategies and tactics for their clients:\n",
      "\n",
      "**Pre-Launch Phase**\n",
      "\n",
      "* Identify and validate a profitable niche or market for your clients\n",
      "* Create a sense of anticipation and expectation by sharing valuable content and insights\n",
      "* Build a list of potential customers and establish a relationship with them\n",
      "* Develop a unique selling proposition (USP) and a compelling story for your clients' products or services\n",
      "\n",
      "**Pre-Launch Sequence**\n",
      "\n",
      "* Create a series of valuable, informative, and engaging content pieces (e.g., videos, blog posts, podcasts) that educate and entertain your audience\n",
      "* Share these content pieces with your list, building anticipation and excitement for the launch\n",
      "* Use this sequence to establish your agency as a thought leader and authority in the niche\n",
      "\n",
      "**Launch Phase**\n",
      "\n",
      "* Create a sense of urgency and scarcity by offering limited-time bonuses, discounts, or exclusive access to your clients' products or services\n",
      "* Use a series of emails and other marketing materials to build excitement and anticipation for the launch\n",
      "* Encourage your audience to take action by offering a clear call-to-action (CTA) and making it easy for them to buy\n",
      "* Use social proof, such as testimonials and reviews, to build credibility and trust\n",
      "\n",
      "**Post-Launch Phase**\n",
      "\n",
      "* Follow up with your audience to ensure they're satisfied with their purchase and to gather feedback\n",
      "* Continue to provide value and support to your audience, building a loyal community around your clients' products or services\n",
      "* Use this opportunity to upsell or cross-sell related products or services, or to promote future launches\n",
      "\n",
      "**Key Principles**\n",
      "\n",
      "* Focus on providing immense value to your audience, rather than just trying to make a sale\n",
      "* Build relationships and trust with your audience, rather than just trying to make a quick buck\n",
      "* Use storytelling and emotional connections to make your clients' products or services more relatable and appealing\n",
      "* Be authentic, transparent, and honest in all your marketing efforts\n",
      "\n",
      "By implementing these strategies and tactics, a growth marketing agency can help their clients successfully launch and market their products or services, building a loyal audience and driving long-term growth and success.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.43s/it]\n",
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /models/Meta-Llama-3-8B-Instruct and are newly initialized: ['model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EaModel(\n",
       "  (base_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  )\n",
       "  (ea_layer): Model(\n",
       "    (embed_tokens): Embedding(128256, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "    (act): SiLU()\n",
       "    (logsoftmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from eagle.model.ea_model import EaModel\n",
    "\n",
    "\n",
    "ea_model = EaModel.from_pretrained(\n",
    "\tbase_model_path='/models/Meta-Llama-3-8B-Instruct',\n",
    "\tea_model_path='yuhuili/EAGLE-LLaMA3-Instruct-8B',\n",
    "\ttorch_dtype=torch.float16,\n",
    "\tdevice_map='cuda',\n",
    ")\n",
    "ea_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ea_model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,  11190,\n",
       "             11,  49150,    323,  10978,  18328,     13,  24119,   4320,    439,\n",
       "           1520,   3725,    439,   3284,     11,   1418,   1694,   6220,     13,\n",
       "            220,   4718,  11503,   1288,    539,   2997,    904,  28856,     11,\n",
       "          89735,     11,  25185,     11,  64882,     11,  21503,     11,  11660,\n",
       "             11,    477,  12079,   2262,     13,   5321,   6106,    430,    701,\n",
       "          14847,    527,  40418,  74315,    323,   6928,    304,   7138,   7255,\n",
       "             77,   1734,   2746,    264,   3488,   1587,    539,   1304,    904,\n",
       "           5647,     11,    477,    374,    539,   2144,   1870,  56887,     11,\n",
       "          10552,   3249,   4619,    315,  36864,   2555,    539,   4495,     13,\n",
       "           1442,    499,   1541,    956,   1440,    279,   4320,    311,    264,\n",
       "           3488,     11,   4587,   1541,    956,   4430,    905,   2038,     13,\n",
       "         128009, 128006,    882, 128007,    271,   9370,   5730,    553,    279,\n",
       "           1925,   6848,    315,  12149,  23074,    596,   5761,  24083,  31922,\n",
       "           1139,  17889,   3585,    439,    433,  18713,   1771,    311,    264,\n",
       "           6650,   8661,   9266,  25976,   1521,  15174,    323,  26411,    369,\n",
       "            872,   8403,   1131, 128009, 128006,  78191, 128007,    271,  39727,\n",
       "          23074,    596,   5761,  24083,  31922,    374,    264,  16195,   8446,\n",
       "            369,  28818,    323,   8661,   3956,    477,   3600,     13,   5810,\n",
       "            596,    264,  12399,    315,    279,   1925,   6848,    304,  17889,\n",
       "           3585,     11,  41891,    311,    264,   6650,   8661,   9266,  25976,\n",
       "           1521,  15174,    323,  26411,    369,    872,   8403,   1473,    334,\n",
       "           4808,   8288,  18930,  28673,  57277,      9,  65647,    323,   9788,\n",
       "            264,  34235,  35149,    477,   3157,    369,    701,   8403,    198,\n",
       "              9,   4324,    264,   5647,    315,  50919,    323,  31293,    555,\n",
       "          11821,  15525,   2262,    323,  26793,    198,      9,   8012,    264,\n",
       "           1160,    315,   4754,   6444,    323,   5813,    264,   5133,    449,\n",
       "           1124,    198,      9,   8000,    264,   5016,  11486,  41180,    320,\n",
       "           2078,     47,      8,    323,    264,  29722,   3446,    369,    701,\n",
       "           8403,      6,   3956,    477,   3600,    271,    334,   4808,   8288,\n",
       "          18930,  29971,  57277,      9,   4324,    264,   4101,    315,  15525,\n",
       "             11,  39319,     11,    323,  23387,   2262,   9863,    320,     68,\n",
       "           1326,   2637,   6946,     11,   5117,   8158,     11,  55346,      8,\n",
       "            430,  39170,    323,  46276,    701,  10877,    198,      9,  12037,\n",
       "           1521,   2262,   9863,    449,    701,   1160,     11,   4857,  50919,\n",
       "            323,  28361,    369,    279,   7195,    198,      9,   5560,    420,\n",
       "           8668,    311,   5813,    701,   9266,    439,    264,   3463,   7808,\n",
       "            323,  11447,    304,    279,  35149,    271,    334,  33167,  28673,\n",
       "          57277,      9,   4324,    264,   5647,    315,  54917,    323,  82484,\n",
       "            555,  10209,   7347,   7394,  33321,     11,  32162,     11,    477,\n",
       "          14079,   2680,    311,    701,   8403,      6,   3956,    477,   3600,\n",
       "            198,      9,   5560,    264,   4101,    315,  14633,    323,   1023,\n",
       "           8661,   7384,    311,   1977,  28361,    323,  50919,    369,    279,\n",
       "           7195,    198,      9,  10984,  61140,    701,  10877,    311,   1935,\n",
       "           1957,    555,  10209,    264,   2867,   1650,   4791,  26115,    320,\n",
       "           1182,     32,      8,    323,   3339,    433,   4228,    369,   1124,\n",
       "            311,   3780,    198,      9,   5560,   3674,  11311,     11,   1778,\n",
       "            439,  84610,    323,   8544,     11,    311,   1977,  38769,    323,\n",
       "           7095,    271,    334,   4226,   8288,  18930,  28673,  57277,      9,\n",
       "          11359,    709,    449,    701,  10877,    311,   6106,    814,   2351,\n",
       "          20097,    449,    872,   7782,    323,    311,   9762,  11302,    198,\n",
       "              9,  15353,    311,   3493,    907,    323,   1862,    311,    701,\n",
       "          10877,     11,   4857,    264,  29947,   4029,   2212,    701,   8403,\n",
       "              6,   3956,    477,   3600,    198,      9,   5560,    420,   6776,\n",
       "            311,  33834,    616,    477,   5425,   1355,    616,   5552,   3956,\n",
       "            477,   3600,     11,    477,    311,  12192,   3938,  38175,    271,\n",
       "            334,   1622,  58014,  57277,      9,  26891,    389,   8405,  38883,\n",
       "            907,    311,    701,  10877,     11,   4856,   1109,   1120,   4560,\n",
       "            311,   1304,    264,   6412,    198,      9,   8012,  12135,    323,\n",
       "           7095,    449,    701,  10877,     11,   4856,   1109,   1120,   4560,\n",
       "            311,   1304,    264,   4062,  22786,    198,      9,   5560,  48929,\n",
       "            323,  14604,  13537,    311,   1304,    701,   8403,      6,   3956,\n",
       "            477,   3600,    810,   1375,  15436,    323,  33352,    198,      9,\n",
       "           2893,  13513,     11,  18300,     11,    323,  10978,    304,    682,\n",
       "            701,   8661,   9045,    271,   1383,  25976,   1521,  15174,    323,\n",
       "          26411,     11,    264,   6650,   8661,   9266,    649,   1520,    872,\n",
       "           8403,   7946,   7195,    323,   3157,    872,   3956,    477,   3600,\n",
       "             11,   4857,    264,  29947,  10877,    323,  10043,   1317,   9860,\n",
       "           6650,    323,   2450,     13, 128009, 128006]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = ea_model.eagenerate(\n",
    "\tinput_ids=input_ids,\n",
    "\t#attention_mask=attention_mask,\n",
    "\tis_llama3=True,\n",
    "\ttemperature=0,\n",
    "\tmax_new_tokens=512,\n",
    "\ttop_p=0,\n",
    "\ttop_k=0,\n",
    ")\n",
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Jeff Walker's Product Launch Formula is a comprehensive strategy for launching and marketing products or services. Here's a summary of the main ideas in bullet points, tailored to a growth marketing agency implementing these strategies and tactics for their clients:\n",
      "\n",
      "**Pre-Launch Phase**\n",
      "\n",
      "* Identify and validate a profitable niche or market for your clients\n",
      "* Create a sense of anticipation and expectation by sharing valuable content and insights\n",
      "* Build a list of potential customers and establish a relationship with them\n",
      "* Develop a unique selling proposition (USP) and a compelling story for your clients' products or services\n",
      "\n",
      "**Pre-Launch Sequence**\n",
      "\n",
      "* Create a series of valuable, informative, and engaging content pieces (e.g., videos, blog posts, podcasts) that educate and entertain your audience\n",
      "* Share these content pieces with your list, building anticipation and excitement for the launch\n",
      "* Use this sequence to establish your agency as a thought leader and authority in the niche\n",
      "\n",
      "**Launch Phase**\n",
      "\n",
      "* Create a sense of urgency and scarcity by offering limited-time bonuses, discounts, or exclusive access to your clients' products or services\n",
      "* Use a series of emails and other marketing materials to build excitement and anticipation for the launch\n",
      "* Encourage your audience to take action by offering a clear call-to-action (CTA) and making it easy for them to buy\n",
      "* Use social proof, such as testimonials and reviews, to build credibility and trust\n",
      "\n",
      "**Post-Launch Phase**\n",
      "\n",
      "* Follow up with your audience to ensure they're satisfied with their purchase and to gather feedback\n",
      "* Continue to provide value and support to your audience, building a loyal community around your clients' products or services\n",
      "* Use this opportunity to upsell or cross-sell related products or services, or to promote future launches\n",
      "\n",
      "**Key Principles**\n",
      "\n",
      "* Focus on providing immense value to your audience, rather than just trying to make a sale\n",
      "* Build relationships and trust with your audience, rather than just trying to make a quick buck\n",
      "* Use storytelling and emotional connections to make your clients' products or services more relatable and appealing\n",
      "* Be authentic, transparent, and honest in all your marketing efforts\n",
      "\n",
      "By implementing these strategies and tactics, a growth marketing agency can help their clients successfully launch and market their products or services, building a loyal audience and driving long-term growth and success.<|eot_id|><|start_header_id|>\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode(output_ids[0], skip_special_tokens=False)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
