{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/work/EAGLE/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 13:37:02,558] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conversation(name='llama-3', system_template='<|start_header_id|>system<|end_header_id|>\\n\\n{system_message}<|eot_id|>', system_message='', system_message_vision='', roles=('user', 'assistant'), messages=[], offset=0, sep_style=<SeparatorStyle.LLAMA3: 8>, sep='', sep2=None, stop_str='<|eot_id|>', stop_token_ids=[128001, 128009], max_image_size_mb=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastchat.model import get_conversation_template\n",
    "\n",
    "\n",
    "conv = get_conversation_template('/models/Meta-Llama-3-8B-Instruct')\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/work/EAGLE/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 11:27:09,849] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/models/Meta-Llama-3-8B-Instruct', use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained('/models/Meta-Llama-3-8B-Instruct', device_map=\"cuda\", torch_dtype=torch.float16)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\\\n\\\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "\t{\"role\": \"system\", \"content\": \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\\\n\\\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"},\n",
    "\t{\"role\": \"user\", \"content\": \"Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...\"},\n",
    "]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "\tconv.append_message(msg['role'], msg['content'])\n",
    "\n",
    "prompt = conv.get_prompt()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 149]),\n",
       " tensor([[128000, 128000, 128006,   9125, 128007,    271,   2675,    527,    264,\n",
       "           11190,     11,  49150,    323,  10978,  18328,     13,  24119,   4320,\n",
       "             439,   1520,   3725,    439,   3284,     11,   1418,   1694,   6220,\n",
       "              13,    220,   4718,  11503,   1288,    539,   2997,    904,  28856,\n",
       "              11,  89735,     11,  25185,     11,  64882,     11,  21503,     11,\n",
       "           11660,     11,    477,  12079,   2262,     13,   5321,   6106,    430,\n",
       "             701,  14847,    527,  40418,  74315,    323,   6928,    304,   7138,\n",
       "            7255,     77,   1734,   2746,    264,   3488,   1587,    539,   1304,\n",
       "             904,   5647,     11,    477,    374,    539,   2144,   1870,  56887,\n",
       "              11,  10552,   3249,   4619,    315,  36864,   2555,    539,   4495,\n",
       "              13,   1442,    499,   1541,    956,   1440,    279,   4320,    311,\n",
       "             264,   3488,     11,   4587,   1541,    956,   4430,    905,   2038,\n",
       "              13, 128009, 128006,    882, 128007,    271,   9370,   5730,    553,\n",
       "             279,   1925,   6848,    315,  12149,  23074,    596,   5761,  24083,\n",
       "           31922,   1139,  17889,   3585,    439,    433,  18713,   1771,    311,\n",
       "             264,   6650,   8661,   9266,  25976,   1521,  15174,    323,  26411,\n",
       "             369,    872,   8403,   1131, 128009]], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(prompt, return_tensors='pt').cuda()\n",
    "input_ids.shape, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(input_ids[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/work/EAGLE/env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 572]),\n",
       " tensor([[128000, 128000, 128006,   9125, 128007,    271,   2675,    527,    264,\n",
       "           11190,     11,  49150,    323,  10978,  18328,     13,  24119,   4320,\n",
       "             439,   1520,   3725,    439,   3284,     11,   1418,   1694,   6220,\n",
       "              13,    220,   4718,  11503,   1288,    539,   2997,    904,  28856,\n",
       "              11,  89735,     11,  25185,     11,  64882,     11,  21503,     11,\n",
       "           11660,     11,    477,  12079,   2262,     13,   5321,   6106,    430,\n",
       "             701,  14847,    527,  40418,  74315,    323,   6928,    304,   7138,\n",
       "            7255,     77,   1734,   2746,    264,   3488,   1587,    539,   1304,\n",
       "             904,   5647,     11,    477,    374,    539,   2144,   1870,  56887,\n",
       "              11,  10552,   3249,   4619,    315,  36864,   2555,    539,   4495,\n",
       "              13,   1442,    499,   1541,    956,   1440,    279,   4320,    311,\n",
       "             264,   3488,     11,   4587,   1541,    956,   4430,    905,   2038,\n",
       "              13, 128009, 128006,    882, 128007,    271,   9370,   5730,    553,\n",
       "             279,   1925,   6848,    315,  12149,  23074,    596,   5761,  24083,\n",
       "           31922,   1139,  17889,   3585,    439,    433,  18713,   1771,    311,\n",
       "             264,   6650,   8661,   9266,  25976,   1521,  15174,    323,  26411,\n",
       "             369,    872,   8403,   1131, 128009, 128006,  78191, 128007,    271,\n",
       "           39727,  23074,    596,   5761,  24083,  31922,    374,    264,  16195,\n",
       "            8641,    311,  28818,    264,   6992,   2027,    477,   2532,     13,\n",
       "            5810,    596,    264,  12399,    315,    279,   1925,   6848,    439,\n",
       "             433,  18713,   1771,    311,    264,   6650,   8661,   9266,  25976,\n",
       "            1521,  15174,    323,  26411,    369,    872,   8403,   1473,    334,\n",
       "            4808,   8288,  18930,  28673,     25,  57277,      9,  65647,    264,\n",
       "            3230,   2218,  10877,    323,   1893,    264,   5016,    907,  41180,\n",
       "             430,  29280,    988,    449,   1124,    198,      9,   8000,    264,\n",
       "           29722,   3446,    323,  30622,    430,  21881,    311,    279,  10877,\n",
       "             596,   6784,   3585,    323,  32097,    198,      9,   8012,    459,\n",
       "            2613,   1160,    323,   1893,    264,   5133,    449,    279,  10877,\n",
       "            1555,  15525,   2262,    323,  20392,    198,      9,  40498,    264,\n",
       "            5647,    315,  50919,    323,  31293,    369,    279,  14827,   7195,\n",
       "             271,    334,   4808,   8288,  18930,  29971,     25,  57277,      9,\n",
       "            4324,    264,   4101,    315,    864,  86406,  14633,    430,   1977,\n",
       "           50919,    323,  28361,     11,   1418,   1101,   8405,    907,    311,\n",
       "             279,  10877,    198,      9,  12037,   4920,  10826,  80645,   2262,\n",
       "              11,  45264,   1069,  21854,     11,    323,  14079,   6209,    311,\n",
       "            2567,    279,  10877,  17045,    198,      9,   5560,    420,   8668,\n",
       "             311,   1977,    264,   5647,    315,   4029,    323,  15253,  10877,\n",
       "           20852,    271,    334,  33167,   6187,     25,  57277,      9,  24083,\n",
       "             279,   2027,    477,   2532,    323,   1304,    433,   2561,    311,\n",
       "             279,  10877,    198,      9,   4324,    264,   5647,    315,  54917,\n",
       "             323,  82484,    555,  10209,   7347,   7394,  32162,     11,  33321,\n",
       "              11,    477,   1023,  36580,    198,      9,   5560,   3674,  11311,\n",
       "             323,  84610,    311,   1977,  38769,    323,   7095,    449,    279,\n",
       "           10877,    198,      9,  10984,  61140,  10877,   3697,    311,   1935,\n",
       "            1957,    323,   1304,    264,   7782,    271,    334,   4226,   8288,\n",
       "           18930,  28673,     25,  57277,      9,  11359,    709,    449,    279,\n",
       "           10877,    311,   6106,    814,   2351,  20097,    449,    872,   7782,\n",
       "             323,    311,   9762,  11302,    198,      9,  25510,   5217,    907,\n",
       "             323,   1862,    311,   1977,    264,  29947,   6130,   2385,    198,\n",
       "               9,  20915,  66735,   8891,    323,  30536,    279,   7195,   1920,\n",
       "             311,   7417,   3938,  38175,    271,    334,   1622,  12040,  40690,\n",
       "             369,  34871,  18729,  91286,     25,  57277,      9,  26891,    389,\n",
       "            4857,    264,   3831,   5133,    449,    279,   2218,  10877,   1555,\n",
       "           15525,   2262,    323,  20392,    198,      9,   5560,    279,    864,\n",
       "           86406,   8668,    311,   1977,  50919,    323,  28361,     11,   1418,\n",
       "            1101,   8405,    907,    311,    279,  10877,    198,      9,   4324,\n",
       "             264,   5647,    315,  54917,    323,  82484,    389,   7195,   1938,\n",
       "             311,  15253,   1957,    198,      9,   5560,   3674,  11311,    323,\n",
       "           84610,    311,   1977,  38769,    323,   7095,    449,    279,  10877,\n",
       "             198,      9,  20915,  66735,   8891,    323,  30536,    279,   7195,\n",
       "            1920,    311,   7417,   3938,  38175,    271,   1383,  25976,   1521,\n",
       "           15174,    323,  26411,     11,   6650,   8661,  13607,    649,   1520,\n",
       "             872,   8403,  11322,   6992,   2027,  38175,    323,   1977,    264,\n",
       "           29947,   6130,   2385,     13, 128009]], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=False,\n",
    "\ttemperature=0,\n",
    ")\n",
    "output.shape, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Jeff Walker's Product Launch Formula is a comprehensive guide to launching a successful product or service. Here's a summary of the main ideas as it pertains to a growth marketing agency implementing these strategies and tactics for their clients:\n",
      "\n",
      "**Pre-Launch Phase:**\n",
      "\n",
      "* Identify a specific target audience and create a unique value proposition that resonates with them\n",
      "* Develop a compelling story and messaging that speaks to the audience's pain points and desires\n",
      "* Build an email list and create a relationship with the audience through valuable content and engagement\n",
      "* Establish a sense of anticipation and expectation for the upcoming launch\n",
      "\n",
      "**Pre-Launch Sequence:**\n",
      "\n",
      "* Create a series of pre-launch emails that build anticipation and excitement, while also providing value to the audience\n",
      "* Share behind-the-scenes content, sneak peeks, and exclusive offers to keep the audience engaged\n",
      "* Use this sequence to build a sense of community and encourage audience participation\n",
      "\n",
      "**Launch Day:**\n",
      "\n",
      "* Launch the product or service and make it available to the audience\n",
      "* Create a sense of urgency and scarcity by offering limited-time discounts, bonuses, or other incentives\n",
      "* Use social proof and testimonials to build credibility and trust with the audience\n",
      "* Encourage audience members to take action and make a purchase\n",
      "\n",
      "**Post-Launch Phase:**\n",
      "\n",
      "* Follow up with the audience to ensure they're satisfied with their purchase and to gather feedback\n",
      "* Offer additional value and support to build a loyal customer base\n",
      "* Continuously monitor and optimize the launch process to improve future launches\n",
      "\n",
      "**Key Takeaways for Growth Marketing Agencies:**\n",
      "\n",
      "* Focus on building a strong relationship with the target audience through valuable content and engagement\n",
      "* Use the pre-launch sequence to build anticipation and excitement, while also providing value to the audience\n",
      "* Create a sense of urgency and scarcity on launch day to encourage action\n",
      "* Use social proof and testimonials to build credibility and trust with the audience\n",
      "* Continuously monitor and optimize the launch process to improve future launches\n",
      "\n",
      "By implementing these strategies and tactics, growth marketing agencies can help their clients achieve successful product launches and build a loyal customer base.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.43s/it]\n",
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /models/Meta-Llama-3-8B-Instruct and are newly initialized: ['model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EaModel(\n",
       "  (base_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  )\n",
       "  (ea_layer): Model(\n",
       "    (embed_tokens): Embedding(128256, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "    (act): SiLU()\n",
       "    (logsoftmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from eagle.model.ea_model import EaModel\n",
    "\n",
    "\n",
    "ea_model = EaModel.from_pretrained(\n",
    "\tbase_model_path='/models/Meta-Llama-3-8B-Instruct',\n",
    "\tea_model_path='yuhuili/EAGLE-LLaMA3-Instruct-8B',\n",
    "\ttorch_dtype=torch.float16,\n",
    "\tdevice_map='cuda',\n",
    ")\n",
    "ea_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ea_model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128000, 128006,   9125, 128007,    271,   2675,    527,    264,\n",
       "          11190,     11,  49150,    323,  10978,  18328,     13,  24119,   4320,\n",
       "            439,   1520,   3725,    439,   3284,     11,   1418,   1694,   6220,\n",
       "             13,    220,   4718,  11503,   1288,    539,   2997,    904,  28856,\n",
       "             11,  89735,     11,  25185,     11,  64882,     11,  21503,     11,\n",
       "          11660,     11,    477,  12079,   2262,     13,   5321,   6106,    430,\n",
       "            701,  14847,    527,  40418,  74315,    323,   6928,    304,   7138,\n",
       "           7255,     77,   1734,   2746,    264,   3488,   1587,    539,   1304,\n",
       "            904,   5647,     11,    477,    374,    539,   2144,   1870,  56887,\n",
       "             11,  10552,   3249,   4619,    315,  36864,   2555,    539,   4495,\n",
       "             13,   1442,    499,   1541,    956,   1440,    279,   4320,    311,\n",
       "            264,   3488,     11,   4587,   1541,    956,   4430,    905,   2038,\n",
       "             13, 128009, 128006,    882, 128007,    271,   9370,   5730,    553,\n",
       "            279,   1925,   6848,    315,  12149,  23074,    596,   5761,  24083,\n",
       "          31922,   1139,  17889,   3585,    439,    433,  18713,   1771,    311,\n",
       "            264,   6650,   8661,   9266,  25976,   1521,  15174,    323,  26411,\n",
       "            369,    872,   8403,   1131, 128009, 128006,  78191, 128007,    271,\n",
       "          39727,  23074,    596,   5761,  24083,  31922,    374,    264,  16195,\n",
       "           8641,    311,  28818,    264,   6992,   2027,    477,   2532,     13,\n",
       "           5810,    596,    264,  12399,    315,    279,   1925,   6848,    439,\n",
       "            433,  18713,   1771,    311,    264,   6650,   8661,   9266,  25976,\n",
       "           1521,  15174,    323,  26411,    369,    872,   8403,   1473,    334,\n",
       "           4808,   8288,  18930,  28673,     25,  57277,      9,  65647,    264,\n",
       "           3230,   2218,  10877,    323,   1893,    264,   5016,    907,  41180,\n",
       "            430,  29280,    988,    449,   1124,    198,      9,   8000,    264,\n",
       "          29722,   3446,    323,  30622,    430,  21881,    311,    279,  10877,\n",
       "            596,   6784,   3585,    323,  32097,    198,      9,   8012,    459,\n",
       "           2613,   1160,    323,   1893,    264,   5133,    449,    279,  10877,\n",
       "           1555,  15525,   2262,    323,  20392,    198,      9,  40498,    264,\n",
       "           5647,    315,  50919,    323,  31293,    369,    279,  14827,   7195,\n",
       "            271,    334,   4808,   8288,  18930,  29971,     25,  57277,      9,\n",
       "           4324,    264,   4101,    315,    864,  86406,  14633,    430,   1977,\n",
       "          50919,    323,  28361,     11,   1418,   1101,   8405,    907,    311,\n",
       "            279,  10877,    198,      9,  12037,   4920,  10826,  80645,   2262,\n",
       "             11,  45264,   1069,  21854,     11,    323,  14079,   6209,    311,\n",
       "           2567,    279,  10877,  17045,    198,      9,   5560,    420,   8668,\n",
       "            311,   1977,    264,   5647,    315,   4029,    323,  15253,  10877,\n",
       "          20852,    271,    334,  33167,   6187,     25,  57277,      9,  24083,\n",
       "            279,   2027,    477,   2532,    323,   1304,    433,   2561,    311,\n",
       "            279,  10877,    198,      9,   4324,    264,   5647,    315,  54917,\n",
       "            323,  82484,    555,  10209,   7347,   7394,  32162,     11,  33321,\n",
       "             11,    477,   1023,  36580,    198,      9,   5560,   3674,  11311,\n",
       "            323,  84610,    311,   1977,  38769,    323,   7095,    449,    279,\n",
       "          10877,    198,      9,  10984,  61140,  10877,   3697,    311,   1935,\n",
       "           1957,    323,   1304,    264,   7782,    271,    334,   4226,   8288,\n",
       "          18930,  28673,     25,  57277,      9,  11359,    709,    449,    279,\n",
       "          10877,    311,   6106,    814,   2351,  20097,    449,    872,   7782,\n",
       "            323,    311,   9762,  11302,    198,      9,  25510,   5217,    907,\n",
       "            323,   1862,    311,   1977,    264,  29947,   6130,   2385,    198,\n",
       "              9,  20915,  66735,   8891,    323,  30536,    279,   7195,   1920,\n",
       "            311,   7417,   3938,  38175,    271,    334,   1622,  12040,  40690,\n",
       "            369,  34871,  18729,  91286,     25,  57277,      9,  26891,    389,\n",
       "           4857,    264,   3831,   5133,    449,    279,   2218,  10877,   1555,\n",
       "          15525,   2262,    323,  20392,    198,      9,   5560,    279,    864,\n",
       "          86406,   8668,    311,   1977,  50919,    323,  28361,     11,   1418,\n",
       "           1101,   8405,    907,    311,    279,  10877,    198,      9,   4324,\n",
       "            264,   5647,    315,  54917,    323,  82484,    389,   7195,   1938,\n",
       "            311,  15253,   1957,    198,      9,   5560,   3674,  11311,    323,\n",
       "          84610,    311,   1977,  38769,    323,   7095,    449,    279,  10877,\n",
       "            198,      9,  20915,  66735,   8891,    323,  30536,    279,   7195,\n",
       "           1920,    311,   7417,   3938,  38175,    271,   1383,  25976,   1521,\n",
       "          15174,    323,  26411,     11,   6650,   8661,  13607,    649,   1520,\n",
       "            872,   8403,  11322,   6992,   2027,  38175,    323,   1977,    264,\n",
       "          29947,   6130,   2385,     13, 128009, 128006,  78191]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = ea_model.eagenerate(\n",
    "\tinput_ids=input_ids,\n",
    "\t#attention_mask=attention_mask,\n",
    "\tis_llama3=True,\n",
    "\ttemperature=0,\n",
    "\tmax_new_tokens=512,\n",
    "\ttop_p=0,\n",
    "\ttop_k=0,\n",
    ")\n",
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Jeff Walker's Product Launch Formula is a comprehensive guide to launching a successful product or service. Here's a summary of the main ideas as it pertains to a growth marketing agency implementing these strategies and tactics for their clients:\n",
      "\n",
      "**Pre-Launch Phase:**\n",
      "\n",
      "* Identify a specific target audience and create a unique value proposition that resonates with them\n",
      "* Develop a compelling story and messaging that speaks to the audience's pain points and desires\n",
      "* Build an email list and create a relationship with the audience through valuable content and engagement\n",
      "* Establish a sense of anticipation and expectation for the upcoming launch\n",
      "\n",
      "**Pre-Launch Sequence:**\n",
      "\n",
      "* Create a series of pre-launch emails that build anticipation and excitement, while also providing value to the audience\n",
      "* Share behind-the-scenes content, sneak peeks, and exclusive offers to keep the audience engaged\n",
      "* Use this sequence to build a sense of community and encourage audience participation\n",
      "\n",
      "**Launch Day:**\n",
      "\n",
      "* Launch the product or service and make it available to the audience\n",
      "* Create a sense of urgency and scarcity by offering limited-time discounts, bonuses, or other incentives\n",
      "* Use social proof and testimonials to build credibility and trust with the audience\n",
      "* Encourage audience members to take action and make a purchase\n",
      "\n",
      "**Post-Launch Phase:**\n",
      "\n",
      "* Follow up with the audience to ensure they're satisfied with their purchase and to gather feedback\n",
      "* Offer additional value and support to build a loyal customer base\n",
      "* Continuously monitor and optimize the launch process to improve future launches\n",
      "\n",
      "**Key Takeaways for Growth Marketing Agencies:**\n",
      "\n",
      "* Focus on building a strong relationship with the target audience through valuable content and engagement\n",
      "* Use the pre-launch sequence to build anticipation and excitement, while also providing value to the audience\n",
      "* Create a sense of urgency and scarcity on launch day to encourage action\n",
      "* Use social proof and testimonials to build credibility and trust with the audience\n",
      "* Continuously monitor and optimize the launch process to improve future launches\n",
      "\n",
      "By implementing these strategies and tactics, growth marketing agencies can help their clients achieve successful product launches and build a loyal customer base.<|eot_id|><|start_header_id|>assistant\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode(output_ids[0], skip_special_tokens=False)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
