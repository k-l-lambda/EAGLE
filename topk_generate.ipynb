{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.84s/it]\n",
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /models/Meta-Llama-3-8B-Instruct and are newly initialized: ['model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nHello World!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " [[128000,\n",
       "   128006,\n",
       "   882,\n",
       "   128007,\n",
       "   271,\n",
       "   9906,\n",
       "   4435,\n",
       "   0,\n",
       "   128009,\n",
       "   128006,\n",
       "   78191,\n",
       "   128007,\n",
       "   271]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from eagle.model.ea_model import EaModel\n",
    "\n",
    "\n",
    "model = EaModel.from_pretrained(\n",
    "    base_model_path='/models/Meta-Llama-3-8B-Instruct',\n",
    "    ea_model_path='yuhuili/EAGLE-LLaMA3-Instruct-8B',\n",
    "    total_token=60,\n",
    "    depth=5,\n",
    "    top_k=10,\n",
    "    #torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "tokenizer = model.get_tokenizer()\n",
    "\n",
    "messages = [\n",
    "\t{\n",
    "\t\t'role': 'user',\n",
    "\t\t'content': 'Hello World!',\n",
    "\t}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "input_ids = tokenizer([prompt], add_special_tokens=False, ).input_ids\n",
    "\n",
    "prompt, input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## eagenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128006,    882, 128007,    271,   9906,   4435,      0, 128009,\n",
       "         128006,  78191, 128007,    271]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eagle.model.kv_cache import initialize_past_key_values\n",
    "\n",
    "\n",
    "input_ids = torch.as_tensor(input_ids)\n",
    "padding = (torch.zeros(1, 1, dtype=torch.long) - 1).to(input_ids.device)\n",
    "\n",
    "model.ea_layer.reset_kv()\n",
    "\n",
    "(\n",
    "    past_key_values,\n",
    "    past_key_values_data,\n",
    "    current_length_data,\n",
    ") = initialize_past_key_values(model.base_model)\n",
    "model.past_key_values = past_key_values\n",
    "model.past_key_values_data = past_key_values_data\n",
    "model.current_length_data = current_length_data\n",
    "\n",
    "# Reset the past key and value states\n",
    "current_length_data.zero_()\n",
    "\n",
    "model.base_model.model.tree_mask = None\n",
    "model.base_model.model.tree_mode = None\n",
    "\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## initialize_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 13, 128256]), torch.Size([1, 13, 4096]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs, orig, hidden_states = model(\n",
    "    input_ids, past_key_values=past_key_values, output_orig=True\n",
    ")\n",
    "\n",
    "orig.shape, hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9906)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = torch.argmax(orig[:, -1])\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 14]),\n",
       " tensor([[128000, 128006,    882, 128007,    271,   9906,   4435,      0, 128009,\n",
       "          128006,  78191, 128007,    271,   9906]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = token[None, None]\n",
    "input_ids = torch.cat((input_ids, token.to(input_ids.device)), dim=1)\n",
    "\n",
    "input_ids.shape, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=128256, bias=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = model.base_model.lm_head\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 13, 4096]), torch.Size([1, 14]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape, input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embed_tokens): Embedding(128256, 4096, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0): LlamaDecoderLayer(\n",
       "      (self_attn): LlamaAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): LlamaMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (post_attention_layernorm): LlamaRMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "  (act): SiLU()\n",
       "  (logsoftmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self = model.ea_layer\n",
    "self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## topK_genrate\n",
    "\n",
    "`genrate` is a typo in EAGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 5, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens = self.total_tokens\n",
    "depth = self.depth\n",
    "top_k = self.top_k\n",
    "\n",
    "total_tokens, depth, top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([9906]), 13)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_token = input_ids[:, -1]\n",
    "\n",
    "scores_list = []\n",
    "parents_list = []\n",
    "ss_token = []\n",
    "\n",
    "input_ids = input_ids[:, 1:]\n",
    "input_ids = input_ids.to(hidden_states.device)\n",
    "\n",
    "len_posi = input_ids.shape[1]\n",
    "self.reset()\n",
    "\n",
    "sample_token, len_posi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(hasattr(self, \"stable_kv\") and self.stable_kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 13, 4096]),\n",
       " torch.Size([1, 8, 13, 128]),\n",
       " torch.Size([1, 8, 13, 128]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_hidden, past_key_values = self(hidden_states, input_ids=input_ids, use_cache=True)\n",
    "out_hidden.shape, past_key_values[0][0].shape, past_key_values[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4096]), torch.Size([1, 128256]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.stable_kv = past_key_values\n",
    "last_hidden = out_hidden[:, -1]\n",
    "\n",
    "last_headout = head(last_hidden)\n",
    "last_hidden.shape, last_headout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1070,    0, 4435,   11, 1578, 2684, 2268, 1203, 1917,  323]]),\n",
       " tensor([[-0.6652, -0.8468, -3.4629, -5.3292, -5.6466, -6.3770, -6.5991, -6.8702,\n",
       "          -7.3081, -7.5023]], grad_fn=<TopkBackward0>))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_p = self.logsoftmax(last_headout)\n",
    "top = torch.topk(last_p, top_k, dim=-1)\n",
    "topk_index, topk_p = top.indices, top.values\n",
    "topk_index, topk_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[-0.6652, -0.8468, -3.4629, -5.3292, -5.6466, -6.3770, -6.5991, -6.8702,\n",
       "           -7.3081, -7.5023]], grad_fn=<UnsqueezeBackward0>)],\n",
       " [tensor([0])],\n",
       " [tensor([[1070,    0, 4435,   11, 1578, 2684, 2268, 1203, 1917,  323]])])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = topk_p[0]\n",
    "scores_list.append(scores[None])\n",
    "parents_list.append(torch.zeros(1, dtype=torch.long, device=scores.device))\n",
    "ss_token.append(topk_index)\n",
    "\n",
    "scores_list, parents_list, ss_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10]),\n",
       " torch.Size([1, 10, 4096]),\n",
       " torch.Size([1, 1, 10, 10]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = topk_index\n",
    "input_hidden = last_hidden[None].repeat(1, top_k, 1)\n",
    "tree_mask = self.tree_mask_init\n",
    "topk_cs_index = torch.arange(top_k, device=self.embed_tokens.weight.device)\n",
    "\n",
    "input_ids.shape, input_hidden.shape, tree_mask.shape, topk_cs_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]]),\n",
       " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mask, topk_cs_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# the loop\n",
    "\n",
    "for i in range(depth):\n",
    "    self.tree_mask = tree_mask\n",
    "    position_ids = len_posi + self.position_ids\n",
    "    # with Timer(\"draft one\"):\n",
    "    out_hidden, past_key_values = self(input_hidden, input_ids=input_ids, past_key_values=past_key_values,\n",
    "                                       position_ids=position_ids, use_cache=True)\n",
    "    len_posi += 1\n",
    "\n",
    "    # with Timer(\"sort1\"):\n",
    "    bias1 = top_k if i > 0 else 0\n",
    "    bias2 = max(0, i - 1)\n",
    "    bias = 1 + top_k ** 2 * bias2 + bias1\n",
    "    parents = (topk_cs_index + bias)\n",
    "    parents_list.append(parents)\n",
    "\n",
    "    last_headout = head(out_hidden[0])\n",
    "    last_p = self.logsoftmax(last_headout)\n",
    "\n",
    "    top = torch.topk(last_p, top_k, dim=-1)\n",
    "    topk_index, topk_p = top.indices, top.values\n",
    "\n",
    "    cu_scores = topk_p + scores[:, None]\n",
    "\n",
    "    topk_cs = torch.topk(cu_scores.view(-1), top_k, dim=-1)\n",
    "    topk_cs_index, topk_cs_p = topk_cs.indices, topk_cs.values\n",
    "    scores = topk_cs_p\n",
    "\n",
    "    out_ids = topk_cs_index // top_k\n",
    "    input_hidden = out_hidden[:, out_ids]\n",
    "    # with Timer(\"2index\"):\n",
    "    #     in_ids = topk_cs_index % top_k\n",
    "    #     input_ids = topk_index[out_ids, in_ids][None]\n",
    "    # with Timer(\"1index\"):\n",
    "    input_ids = topk_index.view(-1)[topk_cs_index][None]\n",
    "    # print(input_ids.equal(input_ids0))\n",
    "\n",
    "    ss_token.append(topk_index)\n",
    "    scores_list.append(cu_scores)\n",
    "    tree_mask = torch.cat((tree_mask[:, :, out_ids], self.tree_mask_init), dim=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'len_posi': 18,\n",
       " 'parents_list': [tensor([0]),\n",
       "  tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "  tensor([11, 21, 31, 22, 23, 24, 25, 26, 51, 27]),\n",
       "  tensor([111, 121, 112, 122, 131, 113, 114, 115, 116, 117]),\n",
       "  tensor([211, 221, 222, 223, 231, 212, 251, 224, 271, 225]),\n",
       "  tensor([311, 312, 351, 313, 314, 341, 321, 391, 381, 342])],\n",
       " 'ss_token': [tensor([[1070,    0, 4435,   11, 1578, 2684, 2268, 1203, 1917,  323]]),\n",
       "  tensor([[    0,  2268,    11,   758,  4999, 15114,  9135, 91597,   374,  1578],\n",
       "          [ 1102, 20776,   353,   358, 14262, 22691,  2181,  9906,  1666, 29959],\n",
       "          [    0,  2268, 91597,  4999,  9135, 15114, 16715,   758, 69322, 36675],\n",
       "          [ 4435,   433, 20776,  1070, 10343, 14262, 10788,  9906, 22691, 24748],\n",
       "          [    0,  2268,   758,    11,  1070,  4999, 91597,  9135, 15114, 16715],\n",
       "          [    0,  2268,    11,   374,   758,  4999, 91597, 15114,  9135,  1578],\n",
       "          [ 9906, 14262,  2181,  2170, 92886,   791,    32, 46078,  3947, 10343],\n",
       "          [    0,  2268,  1070,    11,  1578,   758,   311, 91597,  4999, 15114],\n",
       "          [    0,  2268, 91597,  4999,  9135, 15114, 16715, 69322,   758, 32483],\n",
       "          [    0,   433, 20776,  1131,    11,  4435, 14262, 10788,   264,  1202]]),\n",
       "  tensor([[  1102,  20776,  14262,  22691,   9906, 128009,    353,   2181,  92886,\n",
       "            71641],\n",
       "          [   596,    374,    574,  10379,   5084,    753,   9011,  40929,      6,\n",
       "             5992],\n",
       "          [  1102, 128009,  20776,  22691,   1115,    353,    358,   2650,  29959,\n",
       "            71641],\n",
       "          [  4435,      0,     11,   1070,   1578,  20776,  95185,   2268,  10788,\n",
       "             5127],\n",
       "          [  9906,  14262,  15339,  92886,  22691,  20776,  35184,     82,     63,\n",
       "            95185],\n",
       "          [  2846,   4265,  24748,  10788,  57617,   3077,   9906,   2351,  92886,\n",
       "            15339],\n",
       "          [     0,     11,   4435,   1070,   1578,   2268,  95185,  20776,   1203,\n",
       "              311],\n",
       "          [  4435,   1070,      0,     11,   1578,   2684,  20776,  10343,  51991,\n",
       "             2268],\n",
       "          [  1102,  20776,  14262,  22691,    353,   9906,   2181, 128009,   1666,\n",
       "            71641],\n",
       "          [   596,    374,    574,   5084,  10379,    753,  40929,   5992,  41887,\n",
       "             9011]]),\n",
       "  tensor([[  596,   374,   574, 10379,  5084,   753,  9011, 40929, 41887,  5992],\n",
       "          [10788,   374, 20776, 24748,  1027,  2751,  6555,     6,   264, 14262],\n",
       "          [ 4435,     0,    11,  1578,  1070, 20776, 95185, 10788,   311,  1917],\n",
       "          [   11, 24748,   264,   311, 10788, 20776, 13118,   279,     0, 22691],\n",
       "          [  596,   374,  5084,   574, 10379,   753,  5992,  8111, 10578, 40929],\n",
       "          [    0,  4435,    11,  1578,  1070,   311, 95185, 20776,  2268, 10788],\n",
       "          [ 4435,  1070,     0,    11, 10343,  1578,  1917, 51991, 20776, 32892],\n",
       "          [ 4435,  1070,     0,    11,  1578,  1917,  5127,  2684, 10343, 20776],\n",
       "          [92886, 20776, 33895, 22691,  9906, 14262,  9011,  4435,    12, 95185],\n",
       "          [ 9906, 14262, 15339, 92886, 22691, 20776, 35184, 95185,    82, 57617]]),\n",
       "  tensor([[10788, 20776, 24748,   374, 14262, 92886,  6555, 95185,  1027,     6],\n",
       "          [    0,  4435,    11,   323,  1070,  1917, 20776,   311, 10788,  1578],\n",
       "          [20776, 10788, 24748, 14262,    11,  6555, 92886,     0, 17104,     6],\n",
       "          [    0,  4435,    11,   311,  1070,   323,  1578, 20776,  1917,  2268],\n",
       "          [    0,  2268, 91597,  9135,  4999, 16715, 69322, 15114,   758, 32483],\n",
       "          [24748,    11,   264, 10788, 20776, 22691, 92886,   311, 13118,   279],\n",
       "          [  374, 10788, 20776, 24748,  2751,  6555,   264,  1027,     6,    11],\n",
       "          [ 4435,     0,  1070,  1917,    11, 10343, 51991,  9506,   323,  1578],\n",
       "          [    0,  2268, 91597,  9135, 69322, 16715, 15114,  4999,   758, 32483],\n",
       "          [   11,   323,     0, 20776, 10788, 24748, 92886,   374,  1131,   330]]),\n",
       "  tensor([[     0,   4435,     11,  20776,    323,   1070,  10788,    311,   1917,\n",
       "             1578],\n",
       "          [     0,   4435,     11,    311,    323,   1070,  20776,   1578,   1917,\n",
       "            10788],\n",
       "          [  1102, 128009,  20776,    358,  22691,    353,   1115,  29959,   2650,\n",
       "            71641],\n",
       "          [  4435,      0,   1070,   1917,     11,  10343,  51991,    323,   9506,\n",
       "             5127],\n",
       "          [ 24748,  20776,  10788,  14262,  92886,     11,   6555,  95185,      0,\n",
       "            17104],\n",
       "          [   358,   1102,  20776, 128009,    353,   1666,  14262,  22691,   1717,\n",
       "             2650],\n",
       "          [   358,   1102,  20776, 128009,    353,  14262,   1666,  22691,   2650,\n",
       "             1717],\n",
       "          [  1102, 128009,    358,  20776,   1115,    353,  29959,  22691,  71641,\n",
       "             2650],\n",
       "          [     0,   2268,  91597,   4999,  69322,   9135,  16715,    758,  15114,\n",
       "            36675],\n",
       "          [     0,   2268,  91597,   4999,   9135,  69322,  16715,  15114,    758,\n",
       "            36675]])],\n",
       " 'scores_list': [tensor([[-0.6652, -0.8468, -3.4629, -5.3292, -5.6466, -6.3770, -6.5991, -6.8702,\n",
       "           -7.3081, -7.5023]], grad_fn=<UnsqueezeBackward0>),\n",
       "  tensor([[ -0.6702,  -6.2944,  -9.0029,  -9.4715, -10.1795, -10.3635, -10.4154,\n",
       "           -10.4355, -10.4483, -10.6196],\n",
       "          [ -1.1206,  -3.5758,  -4.6762,  -4.8519,  -4.8912,  -5.3946,  -5.7662,\n",
       "            -5.8502,  -5.8741,  -5.8756],\n",
       "          [ -3.4713,  -8.3246, -12.4143, -13.5769, -13.6677, -13.6788, -13.7338,\n",
       "           -13.8213, -13.8978, -14.2495],\n",
       "          [ -7.0305,  -7.8408,  -7.9561,  -7.9912,  -8.0089,  -8.2320,  -9.0822,\n",
       "            -9.8118,  -9.8637, -10.0830],\n",
       "          [ -5.6519, -11.3376, -14.0401, -14.0632, -14.1375, -14.9283, -14.9962,\n",
       "           -15.0745, -15.2743, -15.4736],\n",
       "          [ -6.3816, -12.3164, -14.6101, -15.1970, -15.3368, -15.8244, -15.8398,\n",
       "           -15.9124, -15.9659, -16.3816],\n",
       "          [ -7.4980,  -7.7314,  -8.8624, -10.5189, -10.6108, -10.8817, -11.0153,\n",
       "           -11.4677, -11.4736, -11.6927],\n",
       "          [ -6.8823, -11.9950, -13.7244, -14.6629, -14.8726, -14.9060, -14.9795,\n",
       "           -15.5694, -15.7705, -15.7787],\n",
       "          [ -7.3124, -12.8927, -16.5082, -17.2616, -17.3211, -17.5785, -17.6446,\n",
       "           -17.8229, -17.8501, -18.1104],\n",
       "          [-10.1198, -10.1374, -10.3172, -10.8209, -10.8993, -10.9352, -11.2908,\n",
       "           -11.4650, -11.5593, -11.9574]], grad_fn=<AddBackward0>),\n",
       "  tensor([[ -1.1083,  -2.7622,  -3.9800,  -4.5180,  -4.7613,  -5.0302,  -5.0636,\n",
       "            -5.0712,  -5.3236,  -5.3318],\n",
       "          [ -1.2153,  -3.5665,  -8.0739,  -8.8606,  -9.2503,  -9.9769, -10.3029,\n",
       "           -10.5714, -10.5922, -10.6235],\n",
       "          [ -3.8223,  -5.7755,  -6.5790,  -7.3373,  -7.6173,  -8.0638,  -8.1030,\n",
       "            -8.4915,  -8.5612,  -8.6525],\n",
       "          [ -5.1358,  -5.3344,  -6.7794,  -7.5171,  -8.0033,  -8.3696,  -8.5955,\n",
       "            -8.6983,  -9.0806,  -9.5350],\n",
       "          [ -6.7652,  -7.7043,  -8.1064,  -8.4900,  -9.4817,  -9.5608,  -9.7607,\n",
       "            -9.7645, -10.0676, -10.1472],\n",
       "          [ -6.9220,  -8.0794,  -8.4067,  -9.3805,  -9.4246,  -9.6309,  -9.6383,\n",
       "            -9.6956,  -9.7189,  -9.8212],\n",
       "          [ -5.5219,  -7.5674,  -7.5906,  -8.8306,  -9.1825,  -9.4377, -10.1486,\n",
       "           -10.2490, -10.5203, -10.6564],\n",
       "          [ -5.7148,  -7.4539,  -7.8681,  -9.9509, -10.8607, -11.3370, -11.4267,\n",
       "           -11.8649, -11.8653, -11.9126],\n",
       "          [ -6.0392,  -8.0636,  -9.2655,  -9.6023,  -9.7371,  -9.8282, -10.0853,\n",
       "           -10.2543, -10.3841, -10.4358],\n",
       "          [ -5.9857,  -7.4225, -12.7161, -13.1473, -13.4155, -14.2542, -14.5934,\n",
       "           -14.7164, -14.7951, -14.9081]], grad_fn=<AddBackward0>),\n",
       "  tensor([[ -1.1869,  -3.7709,  -8.2507,  -8.4906,  -8.8759,  -9.2529, -10.0305,\n",
       "           -10.0548, -10.3770, -10.3955],\n",
       "          [ -3.4938,  -3.5285,  -3.5972,  -4.5509,  -4.7359,  -4.9242,  -4.9611,\n",
       "            -5.1184,  -5.3522,  -5.3705],\n",
       "          [ -3.7430,  -5.5199,  -5.7352,  -7.3391,  -7.4264,  -7.5790,  -7.7692,\n",
       "            -8.2555,  -8.3834,  -8.7068],\n",
       "          [ -6.4893,  -7.2620,  -7.2684,  -7.8738,  -7.8834,  -7.9038,  -7.9192,\n",
       "            -8.1237,  -8.1649,  -8.2222],\n",
       "          [ -3.8911,  -6.5933, -10.7394, -11.1603, -11.8265, -12.1518, -12.3123,\n",
       "           -12.8330, -13.0120, -13.2088],\n",
       "          [ -5.3807,  -5.6142,  -5.9458,  -8.0657,  -8.2612,  -8.8171,  -8.8775,\n",
       "            -8.8958,  -9.3234,  -9.4066],\n",
       "          [ -4.5956,  -8.0102,  -8.7350,  -9.2851, -10.7859, -10.8949, -11.0880,\n",
       "           -11.2084, -11.5298, -11.8539],\n",
       "          [ -4.9853,  -7.1812,  -7.5310,  -8.7338, -10.3689, -11.1027, -11.2339,\n",
       "           -11.2390, -11.2415, -11.4734],\n",
       "          [-10.9018, -11.1783, -11.3042, -11.3730, -11.3825, -11.5169, -11.7130,\n",
       "           -11.7180, -11.7295, -11.7475],\n",
       "          [ -6.8735,  -7.7265,  -8.5560,  -8.8916,  -9.9083,  -9.9482, -10.1653,\n",
       "           -10.4684, -10.5007, -10.7672]], grad_fn=<AddBackward0>),\n",
       "  tensor([[ -3.0775,  -3.1911,  -3.8762,  -4.2580,  -4.8142,  -5.0371,  -5.0574,\n",
       "            -5.2761,  -5.3243,  -5.5567],\n",
       "          [ -4.4279,  -4.7314,  -6.0963,  -7.9035,  -7.9229,  -8.0467,  -8.1992,\n",
       "            -8.3792,  -8.4471,  -8.5715],\n",
       "          [ -7.3106,  -7.5007,  -7.5347,  -7.8668,  -7.9249,  -8.0429,  -8.0455,\n",
       "            -8.1559,  -8.1773,  -8.3359],\n",
       "          [ -4.3586,  -4.6092,  -6.4487,  -8.3172,  -8.5942,  -8.6925,  -9.1420,\n",
       "            -9.3349,  -9.4281,  -9.6220],\n",
       "          [ -3.7457,  -9.8919, -12.6669, -13.6327, -13.7374, -14.0330, -14.1486,\n",
       "           -14.2223, -14.5853, -15.1026],\n",
       "          [ -6.8540,  -6.8677,  -7.5566,  -7.7092,  -7.7743,  -7.9927,  -8.1269,\n",
       "            -8.2256,  -8.3198,  -8.3708],\n",
       "          [ -5.7018,  -6.3318,  -6.6075,  -7.1317,  -7.1574,  -7.3809,  -7.4965,\n",
       "            -7.6012,  -8.1737,  -8.2833],\n",
       "          [ -4.5976,  -8.7778,  -9.0487,  -9.1238,  -9.8439, -11.5830, -12.1955,\n",
       "           -12.4392, -12.4938, -12.8239],\n",
       "          [ -4.5975, -11.0037, -13.6014, -15.3316, -15.4807, -15.5748, -15.6789,\n",
       "           -15.7111, -16.0538, -16.5683],\n",
       "          [ -7.6477,  -7.6652,  -8.7721,  -9.0152,  -9.1108,  -9.1224,  -9.3498,\n",
       "            -9.3684,  -9.4028,  -9.6191]], grad_fn=<AddBackward0>),\n",
       "  tensor([[ -3.9252,  -4.6176,  -5.5305,  -7.3105,  -7.3691,  -7.4588,  -7.5503,\n",
       "            -7.5570,  -7.6745,  -8.0342],\n",
       "          [ -3.7890,  -4.5618,  -5.8112,  -7.5029,  -8.0705,  -8.1728,  -8.4942,\n",
       "            -8.6298,  -9.0515,  -9.1215],\n",
       "          [ -4.4800,  -5.0193,  -6.6416,  -6.8073,  -7.9666,  -8.0141,  -8.0852,\n",
       "            -8.6600,  -8.8013,  -8.9506],\n",
       "          [ -3.9312,  -7.9093,  -8.1956,  -8.4145,  -8.9539, -10.8138, -11.4230,\n",
       "           -11.6236, -11.7968, -11.8023],\n",
       "          [ -7.6133,  -7.6642,  -7.7461,  -8.3583,  -8.4205,  -8.6632,  -8.6706,\n",
       "            -8.9764,  -9.0008,  -9.1526],\n",
       "          [ -5.5144,  -5.9064,  -6.3781,  -6.9731,  -7.2979,  -8.3330,  -8.4722,\n",
       "            -8.7579,  -8.8538,  -8.9737],\n",
       "          [ -5.7243,  -6.0232,  -6.2437,  -7.0584,  -7.4312,  -8.1559,  -8.3426,\n",
       "            -8.5975,  -9.0365,  -9.0793],\n",
       "          [ -5.1547,  -6.2394,  -7.3509,  -7.4754,  -8.9199,  -9.1623,  -9.3219,\n",
       "            -9.3567,  -9.6171,  -9.6928],\n",
       "          [ -4.5981, -12.7922, -13.6551, -15.6636, -15.7087, -15.7421, -16.1006,\n",
       "           -16.6516, -16.6517, -16.7393],\n",
       "          [ -4.6098, -12.6254, -13.4725, -14.8897, -15.1261, -15.3755, -15.5757,\n",
       "           -16.1873, -16.4799, -16.5261]], grad_fn=<AddBackward0>)]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(\n",
    "\tlen_posi=len_posi,\n",
    "\tparents_list=parents_list,\n",
    "\tss_token=ss_token,\n",
    "\tscores_list=scores_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 10]),\n",
       " torch.Size([10, 10]),\n",
       " torch.Size([10, 10]),\n",
       " torch.Size([10, 10]),\n",
       " torch.Size([10, 10]),\n",
       " torch.Size([10, 10])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ss.shape for ss in ss_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([510]), torch.Size([510]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_list = torch.cat(scores_list, dim=0).view(-1)\n",
    "ss_token_list = torch.cat(ss_token, dim=0).view(-1)\n",
    "top_scores = torch.topk(scores_list, total_tokens, dim=-1)\n",
    "\n",
    "scores_list.shape, ss_token_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59]),\n",
       " tensor([  0,  10,   1, 110,  20, 210, 120, 111, 310, 311,   2,  30, 220, 221,\n",
       "         121,  21, 222, 230, 350, 211, 420, 130, 312, 250, 410, 440, 112, 313,\n",
       "         340, 320, 430, 113, 223, 421, 270, 390, 380, 490, 341, 500, 411,  22,\n",
       "         321, 224, 114, 314,  23,  24, 225, 226, 280, 431, 115, 315, 316, 116,\n",
       "         117, 227, 140]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_scores_index = top_scores.indices\n",
    "top_scores_index.shape, top_scores_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59]),\n",
       " tensor([  0,   1,   2,  10,  20,  21,  22,  23,  24,  30, 110, 111, 112, 113,\n",
       "         114, 115, 116, 117, 120, 121, 130, 140, 210, 211, 220, 221, 222, 223,\n",
       "         224, 225, 226, 227, 230, 250, 270, 280, 310, 311, 312, 313, 314, 315,\n",
       "         316, 320, 321, 340, 341, 350, 380, 390, 410, 411, 420, 421, 430, 431,\n",
       "         440, 490, 500]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_scores_index = torch.sort(top_scores_index).values\n",
    "top_scores_index.shape, top_scores_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draft_tokens = ss_token_list[top_scores_index]\n",
    "draft_tokens = torch.cat((sample_token, draft_tokens), dim=0)\n",
    "draft_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  9906,   1070,      0,   4435,      0,   1102,  20776,    353,    358,\n",
       "         14262,      0,   1102,  20776,  14262,  22691,   9906, 128009,    353,\n",
       "          2181,    596,    374,   1102,   4435,    596,    374,  10788,    374,\n",
       "         20776,  24748,   1027,   2751,   6555,      6,   4435,    596,   4435,\n",
       "          4435,  10788,  20776,  24748,    374,  14262,  92886,   6555,      0,\n",
       "          4435,      0,   4435,      0,   4435,      0,      0,   4435,      0,\n",
       "          4435,   1102, 128009,   4435,      0,      0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draft_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59]),\n",
       " tensor([  0,   0,   0,   1,   2,   2,   2,   2,   2,   3,  11,  11,  11,  11,\n",
       "          11,  11,  11,  11,  21,  21,  31,  22, 111, 111, 121, 121, 121, 121,\n",
       "         121, 121, 121, 121, 112, 131, 114, 115, 211, 211, 211, 211, 211, 211,\n",
       "         211, 221, 221, 223, 223, 231, 224, 271, 311, 311, 312, 312, 351, 351,\n",
       "         313, 381, 342]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draft_parents = torch.cat(parents_list, dim=0)[top_scores_index // top_k].long()\n",
    "draft_parents.shape, draft_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59]),\n",
       " tensor([ 0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          4,  4,  9,  5, 10, 10, 18, 18, 18, 18, 18, 18, 18, 18, 11, 20, 13, 14,\n",
       "         22, 22, 22, 22, 22, 22, 22, 24, 24, 26, 26, 32, 27, 34, 36, 36, 37, 37,\n",
       "         47, 47, 38, 48, 46]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_index = torch.searchsorted(top_scores_index, draft_parents - 1, right=False)\n",
    "mask_index.shape, mask_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1,  0,  1,  1,  1,  1,  1,  2,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         4,  4,  9,  5, 10, 10, 18, 18, 18, 18, 18, 18, 18, 18, 11, 20, 13, 14,\n",
       "        22, 22, 22, 22, 22, 22, 22, 24, 24, 26, 26, 32, 27, 34, 36, 36, 37, 37,\n",
       "        47, 47, 38, 48, 46])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_index[draft_parents == 0] = -1\n",
    "mask_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 10,\n",
       " 6,\n",
       " 11,\n",
       " 11,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 12,\n",
       " 21,\n",
       " 14,\n",
       " 15,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 25,\n",
       " 25,\n",
       " 27,\n",
       " 27,\n",
       " 33,\n",
       " 28,\n",
       " 35,\n",
       " 37,\n",
       " 37,\n",
       " 38,\n",
       " 38,\n",
       " 48,\n",
       " 48,\n",
       " 39,\n",
       " 49,\n",
       " 47]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask_index & mask_index_list is the parent indices in draft tokens (60)\n",
    "mask_index = mask_index + 1\n",
    "mask_index_list = mask_index.tolist()\n",
    "mask_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60, 60]),\n",
       " tensor([[ True, False, False,  ..., False, False, False],\n",
       "         [False,  True, False,  ..., False, False, False],\n",
       "         [False, False,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ...,  True, False, False],\n",
       "         [False, False, False,  ..., False,  True, False],\n",
       "         [False, False, False,  ..., False, False,  True]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mask = torch.eye(total_tokens + 1).bool()\n",
    "tree_mask.shape, tree_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True,  True, False,  ..., False, False, False],\n",
       "        [ True, False,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True, False, False,  ...,  True, False, False],\n",
       "        [ True, False, False,  ..., False,  True, False],\n",
       "        [ True, False, False,  ..., False, False,  True]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mask[:, 0] = True\n",
    "tree_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True,  True, False,  ..., False, False, False],\n",
       "        [ True, False,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True, False,  ...,  True, False, False],\n",
       "        [ True, False,  True,  ..., False,  True, False],\n",
       "        [ True, False,  True,  ..., False, False,  True]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(total_tokens):\n",
    "    tree_mask[i + 1].add_(tree_mask[mask_index_list[i]])\n",
    "tree_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-----------------------------------------------------------\n",
      "11----------------------------------------------------------\n",
      "1-1---------------------------------------------------------\n",
      "1--1--------------------------------------------------------\n",
      "11--1-------------------------------------------------------\n",
      "1-1--1------------------------------------------------------\n",
      "1-1---1-----------------------------------------------------\n",
      "1-1----1----------------------------------------------------\n",
      "1-1-----1---------------------------------------------------\n",
      "1-1------1--------------------------------------------------\n",
      "1--1------1-------------------------------------------------\n",
      "11--1------1------------------------------------------------\n",
      "11--1-------1-----------------------------------------------\n",
      "11--1--------1----------------------------------------------\n",
      "11--1---------1---------------------------------------------\n",
      "11--1----------1--------------------------------------------\n",
      "11--1-----------1-------------------------------------------\n",
      "11--1------------1------------------------------------------\n",
      "11--1-------------1-----------------------------------------\n",
      "1-1--1-------------1----------------------------------------\n",
      "1-1--1--------------1---------------------------------------\n",
      "1--1------1----------1--------------------------------------\n",
      "1-1---1---------------1-------------------------------------\n",
      "11--1------1-----------1------------------------------------\n",
      "11--1------1------------1-----------------------------------\n",
      "1-1--1-------------1-----1----------------------------------\n",
      "1-1--1-------------1------1---------------------------------\n",
      "1-1--1-------------1-------1--------------------------------\n",
      "1-1--1-------------1--------1-------------------------------\n",
      "1-1--1-------------1---------1------------------------------\n",
      "1-1--1-------------1----------1-----------------------------\n",
      "1-1--1-------------1-----------1----------------------------\n",
      "1-1--1-------------1------------1---------------------------\n",
      "11--1-------1--------------------1--------------------------\n",
      "1--1------1----------1------------1-------------------------\n",
      "11--1---------1--------------------1------------------------\n",
      "11--1----------1--------------------1-----------------------\n",
      "11--1------1-----------1-------------1----------------------\n",
      "11--1------1-----------1--------------1---------------------\n",
      "11--1------1-----------1---------------1--------------------\n",
      "11--1------1-----------1----------------1-------------------\n",
      "11--1------1-----------1-----------------1------------------\n",
      "11--1------1-----------1------------------1-----------------\n",
      "11--1------1-----------1-------------------1----------------\n",
      "1-1--1-------------1-----1------------------1---------------\n",
      "1-1--1-------------1-----1-------------------1--------------\n",
      "1-1--1-------------1-------1------------------1-------------\n",
      "1-1--1-------------1-------1-------------------1------------\n",
      "11--1-------1--------------------1--------------1-----------\n",
      "1-1--1-------------1--------1--------------------1----------\n",
      "11--1---------1--------------------1--------------1---------\n",
      "11--1------1-----------1-------------1-------------1--------\n",
      "11--1------1-----------1-------------1--------------1-------\n",
      "11--1------1-----------1--------------1--------------1------\n",
      "11--1------1-----------1--------------1---------------1-----\n",
      "11--1-------1--------------------1--------------1------1----\n",
      "11--1-------1--------------------1--------------1-------1---\n",
      "11--1------1-----------1---------------1-----------------1--\n",
      "1-1--1-------------1--------1--------------------1--------1-\n",
      "1-1--1-------------1-------1-------------------1-----------1\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([''.join(map(lambda x: '1' if x else '-', line)) for line in tree_mask.int().tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60]),\n",
       " tensor([0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_position_ids = torch.sum(tree_mask, dim=1) - 1\n",
    "tree_position_ids.shape, tree_position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 60, 60]), torch.Size([1, 60]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mask = tree_mask.float()[None, None]\n",
    "draft_tokens = draft_tokens[None]\n",
    "tree_mask.shape, draft_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = torch.max(tree_position_ids) + 1\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  14,\n",
       "  15,\n",
       "  19,\n",
       "  21,\n",
       "  23,\n",
       "  25,\n",
       "  27,\n",
       "  28,\n",
       "  33,\n",
       "  35,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  47,\n",
       "  48,\n",
       "  49])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noleaf_index = torch.unique(mask_index).tolist()\n",
    "len(noleaf_index), noleaf_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 34)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noleaf_num = len(noleaf_index) - 1\n",
    "leaf_num = total_tokens - noleaf_num\n",
    "noleaf_num, leaf_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1],\n",
       " [-1, -1, -1, -1, -1, -1, -1]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_indices = torch.zeros(leaf_num, max_depth.item(), dtype=torch.long) - 1\n",
    "print(retrieve_indices.shape)\n",
    "\n",
    "retrieve_indices = retrieve_indices.tolist()\n",
    "retrieve_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60]),\n",
       " tensor([0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_position_ids.shape, tree_position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,\n",
       " [[0, 2, 7, -1, -1, -1, -1],\n",
       "  [0, 2, 8, -1, -1, -1, -1],\n",
       "  [0, 2, 9, -1, -1, -1, -1],\n",
       "  [0, 1, 4, 13, -1, -1, -1],\n",
       "  [0, 1, 4, 16, -1, -1, -1],\n",
       "  [0, 1, 4, 17, -1, -1, -1],\n",
       "  [0, 1, 4, 18, -1, -1, -1],\n",
       "  [0, 2, 5, 20, -1, -1, -1],\n",
       "  [0, 2, 6, 22, -1, -1, -1],\n",
       "  [0, 1, 4, 11, 24, -1, -1],\n",
       "  [0, 2, 5, 19, 26, -1, -1],\n",
       "  [0, 2, 5, 19, 29, -1, -1],\n",
       "  [0, 2, 5, 19, 30, -1, -1],\n",
       "  [0, 2, 5, 19, 31, -1, -1],\n",
       "  [0, 2, 5, 19, 32, -1, -1],\n",
       "  [0, 3, 10, 21, 34, -1, -1],\n",
       "  [0, 1, 4, 15, 36, -1, -1],\n",
       "  [0, 1, 4, 11, 23, 40, -1],\n",
       "  [0, 1, 4, 11, 23, 41, -1],\n",
       "  [0, 1, 4, 11, 23, 42, -1],\n",
       "  [0, 1, 4, 11, 23, 43, -1],\n",
       "  [0, 2, 5, 19, 25, 44, -1],\n",
       "  [0, 2, 5, 19, 25, 45, -1],\n",
       "  [0, 2, 5, 19, 27, 46, -1],\n",
       "  [0, 1, 4, 14, 35, 50, -1],\n",
       "  [0, 1, 4, 11, 23, 37, 51],\n",
       "  [0, 1, 4, 11, 23, 37, 52],\n",
       "  [0, 1, 4, 11, 23, 38, 53],\n",
       "  [0, 1, 4, 11, 23, 38, 54],\n",
       "  [0, 1, 4, 12, 33, 48, 55],\n",
       "  [0, 1, 4, 12, 33, 48, 56],\n",
       "  [0, 1, 4, 11, 23, 39, 57],\n",
       "  [0, 2, 5, 19, 28, 49, 58],\n",
       "  [0, 2, 5, 19, 27, 47, 59]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rid = 0\n",
    "position_ids_list = tree_position_ids.tolist()\n",
    "\n",
    "for i in range(total_tokens + 1):\n",
    "    if i not in noleaf_index:\n",
    "        cid = i\n",
    "        depth = position_ids_list[i]\n",
    "        for j in reversed(range(depth + 1)):\t# from the leaf to the root\n",
    "            retrieve_indices[rid][j] = cid\n",
    "            cid = mask_index_list[cid - 1]\n",
    "        rid += 1\n",
    "\n",
    "rid, retrieve_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 60]),\n",
       " torch.Size([34, 7]),\n",
       " torch.Size([1, 1, 60, 60]),\n",
       " torch.Size([60]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_indices = torch.tensor(retrieve_indices, dtype=torch.long)\n",
    "tree_position_ids = tree_position_ids.to(hidden_states.device)\n",
    "\n",
    "draft_tokens.shape, retrieve_indices.shape, tree_mask.shape, tree_position_ids.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
